{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Questions"
      ],
      "metadata": {
        "id": "w5EkZE4u71sM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 1:  What is a Decision Tree, and how does it work in the context of\n",
        "classification?\n",
        "  - Decision Tree is a supervised machine learning algorithm.\n",
        "  - It is used for both classification and regression problems but usually used for classification.\n",
        "  - It seprates data into classes according to their featuers."
      ],
      "metadata": {
        "id": "HcB7lvVd78Fx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 2: Explain the concepts of Gini Impurity and Entropy as impurity measures. How do they impact the splits in a Decision Tree?\n",
        "  - Gini tells us the probablity of wrongly classification of a object.\n",
        "  - Entropy is the measures of disorder or uncertainty in the group.\n",
        "  - It helps in choosing the feature and threshold that produce the largest reduction in impurity."
      ],
      "metadata": {
        "id": "x34fgk5681C3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 3: What is the difference between Pre-Pruning and Post-Pruning in Decision Trees? Give one practical advantage of using each.\n",
        "  - Pre-Prunig mean you stop the tree from growing too much while building it.\n",
        "  - It is nice when you need faster training and simpler trees.\n",
        "  - Post-Pruning mean you first build the full tree, then cut back branches that don’t help much with accuracy.\n",
        "  - It is nice when you need better accuracy and generalization."
      ],
      "metadata": {
        "id": "zdt7XsBy-2Sr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 4: What is Information Gain in Decision Trees, and why is it important for choosing the best split?\n",
        "  - Information gain is amount to information you extract by spliting prant node into children nodes.\n",
        "  - It is important to find the best split because it affects:-\n",
        "    - In finding the best feature to split on.\n",
        "    - Improveing the accuracy by creating nodes that are as pure as possible."
      ],
      "metadata": {
        "id": "FUscUXOL_olx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 5: What are some common real-world applications of Decision Trees, and\n",
        "what are their main advantages and limitations?\n",
        "  - Real world exapmles of Decision tree:-\n",
        "    - Healthcare - Classify whether a patient has a certain disease based on symptoms and test results.\n",
        "    - Agriculture - Classify crop types or predict plant diseases using weather and soil data.\n",
        "    - Quality Control - Detect whether a product is defective or not based on sensor data.\n",
        "    - Marketing - Identify which type of customers are likely to buy a product."
      ],
      "metadata": {
        "id": "ZQN_BEbNAqEW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rtVhKM1U70oX",
        "outputId": "41e1b6b8-f665-40e0-fc32-f03fb3495a8c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy: 0.96\n",
            "\n",
            "Feature Importances:\n",
            "sepal length (cm): 0.0000\n",
            "sepal width (cm): 0.0191\n",
            "petal length (cm): 0.5517\n",
            "petal width (cm): 0.4293\n"
          ]
        }
      ],
      "source": [
        "# Question 6:   Write a Python program to:\n",
        "#● Load the Iris Dataset\n",
        "#● Train a Decision Tree Classifier using the Gini criterion\n",
        "#● Print the model’s accuracy and feature importances\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=2)\n",
        "\n",
        "clf = DecisionTreeClassifier(criterion='gini', random_state=42)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Model Accuracy: {accuracy:.2f}\")\n",
        "\n",
        "print(\"\\nFeature Importances:\")\n",
        "for feature_name, importance in zip(iris.feature_names, clf.feature_importances_):\n",
        "    print(f\"{feature_name}: {importance:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Question 7:  Write a Python program to:\n",
        "#● Load the Iris Dataset\n",
        "#● Train a Decision Tree Classifier with max_depth=3 and compare its accuracy to a fully-grown tree.\n",
        "\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "full_tree = DecisionTreeClassifier(criterion='gini', random_state=5)\n",
        "full_tree.fit(X_train, y_train)\n",
        "\n",
        "limited_tree = DecisionTreeClassifier(criterion='gini', max_depth=3, random_state=42)\n",
        "limited_tree.fit(X_train, y_train)\n",
        "\n",
        "y_pred_full = full_tree.predict(X_test)\n",
        "y_pred_limited = limited_tree.predict(X_test)\n",
        "\n",
        "accuracy_full = accuracy_score(y_test, y_pred_full)\n",
        "accuracy_limited = accuracy_score(y_test, y_pred_limited)\n",
        "\n",
        "print(f\"Accuracy of Fully-Grown Tree: {accuracy_full:.2f}\")\n",
        "print(f\"Accuracy of Tree with max_depth=3: {accuracy_limited:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lKdB8ZLXC-x6",
        "outputId": "915d6f6d-bce9-4d8b-aba3-ebec314ac0b1"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of Fully-Grown Tree: 1.00\n",
            "Accuracy of Tree with max_depth=3: 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Question 8: Write a Python program to:\n",
        "#● Load the Boston Housing Dataset\n",
        "#● Train a Decision Tree Regressor\n",
        "#● Print the Mean Squared Error (MSE) and feature importances\n",
        "\n",
        "# Boston Data is removed from sklearn dataset\n",
        "\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "boston = fetch_openml(name=\"boston\", version=1, as_frame=True)\n",
        "X = boston.data\n",
        "y = boston.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "regressor = DecisionTreeRegressor(criterion='squared_error', random_state=42)\n",
        "regressor.fit(X_train, y_train)\n",
        "\n",
        "y_pred = regressor.predict(X_test)\n",
        "\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(f\"Mean Squared Error (MSE): {mse:.2f}\")\n",
        "\n",
        "print(\"\\nFeature Importances:\")\n",
        "for feature_name, importance in zip(X.columns, regressor.feature_importances_):\n",
        "    print(f\"{feature_name}: {importance:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nj_eVk2RDqKH",
        "outputId": "3b4426ec-881a-461e-b057-1fb0ffcb5866"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Squared Error (MSE): 11.59\n",
            "\n",
            "Feature Importances:\n",
            "CRIM: 0.0585\n",
            "ZN: 0.0010\n",
            "INDUS: 0.0099\n",
            "CHAS: 0.0003\n",
            "NOX: 0.0071\n",
            "RM: 0.5758\n",
            "AGE: 0.0072\n",
            "DIS: 0.1096\n",
            "RAD: 0.0016\n",
            "TAX: 0.0022\n",
            "PTRATIO: 0.0250\n",
            "B: 0.0119\n",
            "LSTAT: 0.1900\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Question 9: Write a Python program to:\n",
        "#● Load the Iris Dataset\n",
        "#● Tune the Decision Tree’s max_depth and min_samples_split using GridSearchCV\n",
        "#● Print the best parameters and the resulting model accuracy\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.3, random_state=42\n",
        ")\n",
        "\n",
        "dt = DecisionTreeClassifier(random_state=42)\n",
        "\n",
        "param_grid = {\n",
        "    'max_depth': [2, 3, 4, 5, None],\n",
        "    'min_samples_split': [2, 3, 4, 5, 10]\n",
        "}\n",
        "\n",
        "grid_search = GridSearchCV(\n",
        "    estimator=dt,\n",
        "    param_grid=param_grid,\n",
        "    cv=5,\n",
        "    scoring='accuracy',\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "best_params = grid_search.best_params_\n",
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "print(\"Best Parameters Found:\")\n",
        "print(best_params)\n",
        "\n",
        "y_pred = best_model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(f\"\\nModel Accuracy with Best Parameters: {accuracy:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_GKnPrLoEh48",
        "outputId": "f3cc3fb0-1e1b-49c9-ba2f-3734a5e607c4"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters Found:\n",
            "{'max_depth': 4, 'min_samples_split': 10}\n",
            "\n",
            "Model Accuracy with Best Parameters: 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 10: Imagine you’re working as a data scientist for a healthcare company that\n",
        "wants to predict whether a patient has a certain disease. You have a large dataset with\n",
        "mixed data types and some missing values.\n",
        "  - Step 1: Handling Missing Values:-\n",
        "    - Identify missing data.\n",
        "    - Impute missing values.\n",
        "  - Step 2: Encoding Categorical Features:-\n",
        "    - Use One-Hot Encoding to encode categorical data.\n",
        "  - Step 3: Training a Decision Tree Model:-\n",
        "    - Split the dataset into training and testing sets.\n",
        "    - Create a DecisionTreeClassifier and train it on the training data.\n",
        "  - Step 4: Hyperparameter Tuning:-\n",
        "    - Use GridSearchCV or RandomizedSearchCV with cross-validation to find the best combination of hyperparameters.\n",
        "  - Step 5: Model Evaluation:-\n",
        "    - Evaluate using appropriate metrics - Accuracy, Precision and Recall, F1-Score"
      ],
      "metadata": {
        "id": "gYvs3iu8Fu2S"
      }
    }
  ]
}