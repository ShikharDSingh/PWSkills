{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Assignment Questions"
      ],
      "metadata": {
        "id": "oc2YuF0GnIzW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.What is a parameter?\n",
        "  - A parameter can be defined as a numerical value that describes a characteristic of a population.\n",
        "  - We often take a sample from poplation and calculate statistic parameters like Mean, Median, Mode, etc.\n",
        "  - These values are usefull for us to give insight about data."
      ],
      "metadata": {
        "id": "3J1Bw2InnMVi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.What is correlation? What does negative correlation mean?\n",
        "  - Correlation is a statistical measure that describes the strength and direction of a relationship between two variables.\n",
        "  - It ranges from -1 to +1.\n",
        "  - A negative correlation means that increases in one variable will lead to decrease in the other.\n",
        "  - Scatter plot of negative correlation will be going down when moving towards right."
      ],
      "metadata": {
        "id": "op9TBESO2D0q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.Define Machine Learning. What are the main components in Machine Learning?\n",
        "  - Machine Learning is a branch of artificial intelligence which focuses on building systems that can learn from the pattern in the data and make\n",
        "  predictions without being explicitly programmed for each task.\n",
        "  - Main components in Machine Learning are:-\n",
        "    - Data:- The raw data used to train the model.\n",
        "    - Features:- Attributes extracted from the data.\n",
        "    - Algorithm:- The method used to train the model.\n",
        "    - Model:- It find pattern in data."
      ],
      "metadata": {
        "id": "JI4p1UQT3Msw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "4.How does loss value help in determining whether the model is good or not?\n",
        "  - The loss value is a number that tells you how much difference in between your model's predictions and the actual values.\n",
        "  - If the loss value is low then your model predicting vaules near actual values and your model is good.\n",
        "  - If the loss value is high it means your model's pridictions are far from actual value and your model is not good."
      ],
      "metadata": {
        "id": "SH5h72uV4yzw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "5.What are continuous and categorical variables?\n",
        "  - Continuous variables:-\n",
        "    - It is a value that can take on any value within a given range.\n",
        "    - It can be decimal data or an integer.\n",
        "    - There can be infinite number of continious variables.\n",
        "  - Categorical variable:-\n",
        "    - Categorical variables represent groups or categories.\n",
        "    - They cant be measured but categorized.\n",
        "    - These are in a limited number."
      ],
      "metadata": {
        "id": "wCUts4w7640A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " 6.How do we handle categorical variables in Machine Learning? What are the common techniques?\n",
        "  - Techniques to handle categorical variables are:-\n",
        "    - Label encoding:- It converts each category into a unique integer like 0,1,2,3.\n",
        "    - One Hot encoding:- It creates a new binary column for each category.\n",
        "    - Ordinal encoding:- It assigns numeric values based on a defined order like 1,2,3.\n",
        "    - Target encoding:- It replaces each category with the mean of the target variable for that category."
      ],
      "metadata": {
        "id": "5s_KWaQt89oB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "7.What do you mean by training and testing a dataset?\n",
        "  - In machine learning we split dataset into two parts training and testing.\n",
        "  - The ratio of split is generally 80:20.\n",
        "  - The training set is the portion of the data used to train the model.\n",
        "  - The testing set is a separate portion of the data used to evaluate the model's performance on unseen data."
      ],
      "metadata": {
        "id": "jhVftv2a_b0E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "8.What is sklearn.preprocessing?\n",
        "  - `sklearn.preprocessing` is a module in Scikit-learn library.\n",
        "  - It provides functions for preprocessing data before feeding it into machine learning models.\n",
        "  - It provides functions like:-\n",
        "    - `StandardScaler`:- It scale features to have mean=0 and std=1.\n",
        "    - `MinMaxScaler`:- It scale features to a 0-1 range.\n",
        "    - `LabelEncoder`:- It encode categorical labels as integers."
      ],
      "metadata": {
        "id": "Sh9qIPn9AjWj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "9.What is a Test set?\n",
        "  - Test set is a portion of your dataset that is used to evaluate the performance of a trained machine learning model.\n",
        "  - It is feeded into machine lerning model after training to check how accuratly model is making pridictions."
      ],
      "metadata": {
        "id": "UnvQl2MoB7kg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "10.How do we split data for model fitting (training and testing) in Python? How do you approach a Machine Learning problem?\n",
        "  - In Python we mostly use Scikit-learn library for data splitting.\n",
        "  - Scikit-learn provides the function `train_test_split()` to split your data into training and testing sets.\n",
        "  - You can use `train_test_split()` to split the data.\n",
        "  - And you can control the size of the test set using the `test_size` parameter it is usually 20%-30% for testing.\n",
        "  - Approaching a Machine Learning problem:-\n",
        "    - Step 1: Define the Problem.\n",
        "    - Step 2: Data Collection.\n",
        "    - Step 3: Data Preprocessing.\n",
        "    - Step 4: Data Splitting.\n",
        "    - Step 5: Model Selection.\n",
        "    - Step 6: Model Training.\n",
        "    - Step 7: Model Evaluation."
      ],
      "metadata": {
        "id": "6pPegvFF8ds3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "11.Why do we have to perform EDA before fitting a model to the data?\n",
        "  - EDA stnds for Exploratory Data Analysis.\n",
        "  - We perform EDA to:-\n",
        "    - Visualization:- During EDA, you create visualizations like histograms, scatter plots, boxplots, etc that provide valuable insights.\n",
        "    - Understanding the data:- It provides insights into the distribution of features the relationship between variables and any potential issues like missing values and outliers in data.\n",
        "    - Dealing with missing data:- Missing data is filled with some data or we completly drop that column.\n",
        "    - Outlier Detection:- Handling outliers as they can significantly affect the performance of machine learning models."
      ],
      "metadata": {
        "id": "_Qu-L4os_SN4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "12.What is correlation?\n",
        "  - Correlation is a statistical measure that describes the strength and direction of a relationship between two variables.\n",
        "  - It ranges from -1 to +1.\n",
        "  - If its value is positive then increase of one value will increase the other.\n",
        "  - If its value is negative then increase of one value decreases the other."
      ],
      "metadata": {
        "id": "aOg65A7QBJbo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "13.What does negative correlation mean?\n",
        "  - A negative correlation means that increases in one variable will lead to decrease in the other.\n",
        "  - Scatter plot of negative correlation will be going down when moving towards right."
      ],
      "metadata": {
        "id": "zOlpFhAvBvCL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "14.How can you find correlation between variables in Python?\n",
        "  - In Python you can find correlation using Pandas library.\n",
        "  - It contains a method calld `corr` which return correlation value.\n",
        "  - Example:-"
      ],
      "metadata": {
        "id": "FtXUsQ3mB63F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.DataFrame({\n",
        "    'A': [1, 2, 3, 4, 5],\n",
        "    'B': [5, 4, 3, 2, 1],\n",
        "    'C': [2, 3, 4, 5, 6],\n",
        "})\n",
        "\n",
        "corr_matrix = df.corr()\n",
        "print(corr_matrix)"
      ],
      "metadata": {
        "id": "m0crjWsL172_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0fec7e73-31ed-4595-fd43-2ec3bfd116f6"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     A    B    C\n",
            "A  1.0 -1.0  1.0\n",
            "B -1.0  1.0 -1.0\n",
            "C  1.0 -1.0  1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "15.What is causation? Explain difference between correlation and causation with an example.\n",
        "  - Causation means that a change in one variable directly causes a change in another.\n",
        "  - Whereas correlation means that two variables are related to each other.\n",
        "  - Example:-\n",
        "    - Observation: People with higher education levels tend to earn more money.\n",
        "    - Correlation: Higher education -> Higher income\n",
        "    - Causation: No guaranty."
      ],
      "metadata": {
        "id": "N-jR9whhDbjK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "16.What is an Optimizer? What are different types of optimizers? Explain each with an example.\n",
        "  - An optimizer is an algorithm that adjusts the model’s parameters during training to minimize the loss function.\n",
        "  - Different types of optimizers:-\n",
        "    - Stochastic Gradient Descent (SGD):-\n",
        "      - It updates weights using the gradient of the loss function.\n",
        "    - Adagrad (Adaptive Gradient Algorithm):-\n",
        "      - It adapts the learning rate for each parameter individually based on how frequently it updates.\n",
        "    - RMSprop (Root Mean Square Propagation):-\n",
        "      - It fixes Adagrad’s problem of decreasing learning rate.\n",
        "      - It uses exponential moving average of squared gradients."
      ],
      "metadata": {
        "id": "2VlYDLb4GgXq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "17.What is sklearn.linear_model?\n",
        "  - `sklearn.linear_model` is a module in the Scikit-learn library that provides a collection of linear models for regression and classification tasks.\n",
        "  - Some of the most commonly used models:-\n",
        "    - LinearRegression\n",
        "    - LogisticRegression\n",
        "    - Ridge Regression\n",
        "    - Lasso Regression"
      ],
      "metadata": {
        "id": "YLsTK_VsINBn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "18.What does model.fit() do? What arguments must be given?\n",
        "  - The `model.fit()` method is used to train your machine learning model on the data.\n",
        "  - Arguments given in `.fit()` method are:-\n",
        "    - Input data:- This contains your input data in the form of pd.dataframe.\n",
        "    - Target:- This is the pridictions you want to make."
      ],
      "metadata": {
        "id": "Y35nKdzAJWVk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "19.What does model.predict() do? What arguments must be given?\n",
        "  - The `model.predict()` method in Scikit-learn is used to make predictions on new unseen data using the ml model.\n",
        "  - Arguments given in `.pridict()` method are:-\n",
        "    - Input data:- This is the only argumnet given in this method.\n",
        "    - It is in pd.dataframe."
      ],
      "metadata": {
        "id": "G0gNmG4cKeN_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "20.What are continuous and categorical variables?\n",
        "  - Continuous variables:-\n",
        "    - It is a value that can take on any value within a given range.\n",
        "    - It can be decimal data or an integer.\n",
        "    - There can be infinite number of continious variables.\n",
        "  - Categorical variable:-\n",
        "    - Categorical variables represent groups or categories.\n",
        "    - They cant be measured but categorized.\n",
        "    - These are in a limited number."
      ],
      "metadata": {
        "id": "hCYSUBIeL3Do"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "21.What is feature scaling? How does it help in Machine Learning?\n",
        "  - Feature scaling is the process of standardizing or normalizing the range of features so that they are on a similar scale.\n",
        "  - ML algorithms are sensitive to the scale of input data.\n",
        "  - If one feature has a large scale and another has a small scale the model may give more weight to the larger feature.\n",
        "  - Even if it's not more important feature."
      ],
      "metadata": {
        "id": "Aetc0DeaMHn2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "22.How do we perform scaling in Python?\n",
        "  - We can perform scaling in Python using `sklearn.preprocessing` module.\n",
        "  - Using StandardScaler:-"
      ],
      "metadata": {
        "id": "yALDO01gM-m-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "X = [[1, 200],\n",
        "     [2, 300],\n",
        "     [3, 400]]\n",
        "\n",
        "scaler = StandardScaler()\n",
        "\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "print(X_scaled)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0gvzMSo4DV45",
        "outputId": "0583189f-bdde-462d-e004-f3571540c191"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-1.22474487 -1.22474487]\n",
            " [ 0.          0.        ]\n",
            " [ 1.22474487  1.22474487]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "  - Using MinMaxScaler:-"
      ],
      "metadata": {
        "id": "3c0iv1O0OGuE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "X = [[1, 200],\n",
        "     [2, 300],\n",
        "     [3, 400]]\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "print(X_scaled)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QhA7feX6OFaN",
        "outputId": "c2c6d46c-cd47-4d81-9260-71ca4f6c9209"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.  0. ]\n",
            " [0.5 0.5]\n",
            " [1.  1. ]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "  - Using RobustScaler:-"
      ],
      "metadata": {
        "id": "cGdviHjfOVF4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import RobustScaler\n",
        "\n",
        "X = [[1, 200],\n",
        "     [2, 300],\n",
        "     [3, 400],\n",
        "     [1000, 9999]]\n",
        "\n",
        "scaler = RobustScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "print(X_scaled)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TzqzeTPQOP4n",
        "outputId": "24982cc7-0c2c-40ef-9994-ad087b15f395"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-5.98802395e-03 -5.94118230e-02]\n",
            " [-1.99600798e-03 -1.98039410e-02]\n",
            " [ 1.99600798e-03  1.98039410e-02]\n",
            " [ 3.98203593e+00  3.82176453e+00]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "23.What is sklearn.preprocessing?\n",
        "  - `sklearn.preprocessing` is a module in Scikit-learn library.\n",
        "  - It provides functions for preprocessing data before feeding it into machine learning models.\n",
        "  - It provides functions like:-\n",
        "    - `StandardScaler`:- It scale features to have mean=0 and std=1.\n",
        "    - `MinMaxScaler`:- It scale features to a 0-1 range.\n",
        "    - `LabelEncoder`:- It encode categorical labels as integers."
      ],
      "metadata": {
        "id": "KxiekV_hOg94"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "24.How do we split data for model fitting (training and testing) in Python?\n",
        "  - In Python we mostly use Scikit-learn library for data splitting.\n",
        "  - Scikit-learn provides the function `train_test_split()` to split your data into training and testing sets.\n",
        "  - You can use `train_test_split()` to split the data.\n",
        "  - And you can control the size of the test set using the `test_size` parameter it is usually 20%-30% for testing.\n",
        "  - Example:-"
      ],
      "metadata": {
        "id": "Mt43fJELO6cP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = [[1], [2], [3], [4], [5], [6]]\n",
        "y = [10, 20, 30, 40, 50, 60]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "print(\"Training data:\", X_train, y_train)\n",
        "print(\"Testing data:\", X_test, y_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IrOZjF1wOeaE",
        "outputId": "e84eed9f-c8f8-427a-89c2-e9275b7a9118"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data: [[3], [2], [5], [4]] [30, 20, 50, 40]\n",
            "Testing data: [[1], [6]] [10, 60]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "25.Explain data encoding?\n",
        "  - Data encoding is the process of converting categorical data into a numerical format so that machine learning algorithms can understand and process it.\n",
        "  - Example:-"
      ],
      "metadata": {
        "id": "dbWwAHH5PhHB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "data = ['small', 'medium', 'large']\n",
        "encoder = LabelEncoder()\n",
        "encoded = encoder.fit_transform(data)\n",
        "\n",
        "print(encoded)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "THCekirnPdin",
        "outputId": "97046c13-3a94-44dc-fae4-9620b43f327e"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[2 1 0]\n"
          ]
        }
      ]
    }
  ]
}